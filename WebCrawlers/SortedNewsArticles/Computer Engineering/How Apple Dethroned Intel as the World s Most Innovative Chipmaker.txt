Back in 2013,Apple(NASDAQ:AAPL) introduced the A7 system on a chip (SoC) as part of its then-flagship smartphone, the iPhone 5s. The A7 was impressive for several reasons. Firstly, it was the very first 64-bit ARM processor to ever hit the market, which gave Apple some performance and efficiency advantages over its fellow mobile competitors (who, rather comically, tried to downplay the need for 64-bit chips as they furiously worked on their own).

What caught my attention at the time, though, was that the A7 delivered CPU performance at a frequency of 1.3 gigahertz that was very similar to chip giantIntel's (NASDAQ:INTC) very best processor, known as Haswell, at the same frequency. Now, Intel's chips, at the time, ran at much higher frequencies (in excess of 3 gigahertz), but what the strong per-gigahertz performance of the A7 chip signaled to me was that Apple had built a very impressive base from which to build up in future smartphone chips.

Fast forward to today, and Apple's best iPhone and iPad processors deliver performance for CPU tasks -- Intel's specialty -- that's competitive with Intel's best notebook computer processors but in sleeker, lower-power devices than what Intel's chips can fit into.

I believe that when Apple introduces its next iPhone in about four months, it will deliver equal or better CPU performance to Intel's best notebook processors designed to consume 15 watts but at a fraction of the power consumption.

Intel, in my view, will be shown to be a clear No. 2 in high-performance, low-power processor design, behind Apple. This not only looks bad for Intel (since much of Intel's brand value is predicated on its being perceived as the maker of the world's best processors) but it could have serious financial implications later down the line.

Let's look at how both Intel and Apple ended up where they are relative to one another.

The quality of a processor is largely determined by its design -- the better the design, the faster and more efficient it'll be. Apple's first in-house processor core, known as Swift, delivered performance that was right up there with Arm Holdings' then-flagship Cortex A15 processor core, but the A6 was earlier to market and arguably more power-efficient.

Every year since the introduction of the Swift processor core inside the A6, Apple has rolled out new processor cores, with each new processor core incorporating substantial design improvements.

But while Apple is great at chip design, it doesn't manufacture its own chips -- it outsources production to third parties. Apple's A-series chips through the A7 were manufactured exclusively bySamsung(NASDAQOTH:SSNLF), andTaiwan Semiconductor Manufacturing Company(NYSE:TSM) was the exclusive manufacturer of the A8, A10, and A11 chips. TSMC and Samsung reportedly split the orders for the A9.

Both TSMC and Samsung have delivered new manufacturing technologies at a breakneck pace. The performance, power consumption, and economic viability of a chip are determined heavily by the technologies upon which it's manufactured.

Apple's A7 chip was built using Samsung's 28-nanometer technology, the A8 chip was manufactured using TSMC's 20nm technology, the A9 was manufactured by either TSMC or Samsung on their respective 16nm and 14nm technologies, the A10 using an upgraded version of TSMC's 16nm technology, and the A11 using TSMC's 10nm technology.

Apple's upcoming A12 processor is believed to have gone into mass production recently using TSMC's latest 7nm technology.

Each of those manufacturing technologies has brought performance, power consumption, and area benefits over its predecessors, allowing Apple's chip designers to deliver increasingly capable processors.

The combination of Apple's chip-design prowess and a highly capable ecosystem of contract chip-manufacturing partners has led to some huge advances in mobile computing.

Unfortunately, as bright as things have been for Apple, the situation has been much less rosy for Intel.

For years, Intel had a clear leadership position in chip-manufacturing technology over the contract chip-manufacturing companies. Intel's technologies tended to be, at any given time, denser than what the competition brought to market -- and, more importantly, they incorporated more advanced transistor technologies than the competition did, allowing Intel to deliver better-performing and more efficient chips than its competition did.

Unfortunately, while TSMC's manufacturing transitions have gone as expected for years, Intel's haven't. For some perspective, Intel's 14nm technology was delayed by about six months, and its 10nm technology has been delayed by more than three years (it's still not in volume production as of this writing; Intel's current claim is that it'll go into production at some point in 2019).

Intel has put out enhanced versions of its 14nm technology (known as 14nm+ and 14nm++) to try to hold the line as it works out the issues with its 10nm technology -- a strategy that's been successful so far -- but the problem is that Intel didn't really plan for these delays. So from a product perspective, Intel couldn't bring out fundamentally new designs based on those tweaked versions of 14nm.

Beginning in 2015, Apple has released three SoCs -- A9, A10, and A11. Each of those chips has had enhanced processor cores, graphics processors, memory subsystems, and all of the other goodies that make chips more powerful and power-efficient. Later this year, Apple will introduce an A12 chip that should incorporate substantial advances across the board.

Intel, however, is expected to release a new wave of processors for laptop computers known as Whiskey Lakebuilt using its 14nm technology (likely 14nm++) that likely won't have any real design improvements -- it should be the same basic processor technology that Intel has been selling since 2015.

Since Apple has managed to aggressively innovate in terms of chip design and has had access to significant improvements in chip-manufacturing technology over the years, it's little wonder that its processors continue to see performance, power consumption, and feature improvements that simply outclass what Intel has brought to market over the last three years.

To be quite blunt, given the relatively anemic pace of processor innovation on Intel's part (which, admittedly, has more to do with manufacturing stumbles and poor planning than with Intel's ability to engineer new processors) and the unreliability of Intel's manufacturing, I can see why the rumors that Apple is planning to ditch Intel in future Mac personal computers are becoming louder and more credible with each passing year.

At some point, Apple's processor designs could be so far ahead of Intel's in all relevant metrics that Apple would actually be doing its Mac products a disservice by not switching over to its own chips. Furthermore, if it can open a comfortable lead over Intel, Apple could use the superiority of its in-house designed processors as a key marketing point against the hordes of Windows-based computers that use Intel processors.

As I've written before, Apple probably buys in the neighborhood of $3 billionin chips from Intel annually, so losing Apple would certainly sting Intel's financials. Another issue for Intel, though, is that if Apple cuts Intel out and can successfully convince the broader public that computers with its own chips are much faster and deliver a superior user experience to Intel-powered computers from Apple's competitors, Apple could make further gains in the personal computer market -- to Intel's detriment.

Ultimately, I think Apple is the most innovative chip designer in the world right now thanks to a combination of world-class engineering talent, exceptional management, and access to dependable manufacturing partners. Not only has Apple taken the lead over Intel, but I think that lead will continue to widen for years to come. In the short term, Apple's chip-development prowess relative to Intel may lead to perception problems for Intel, but over the long term, if Intel falls too far behind, it could permanently lose billions in annual revenue should Apple decide that it's had enough of Intel's poor execution.